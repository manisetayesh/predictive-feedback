{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "from models.mlp import *\n",
    "from models.hebbian import *\n",
    "from models.hybrid import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples retained:\n",
      "  279173 (training)\n",
      "  69793 (validation)\n",
      "  348966 (test)\n"
     ]
    }
   ],
   "source": [
    "def download_dataset(train_prop=0.8, keep_prop=0.5, ds_name=None):\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if ds_name is None:\n",
    "        download = os.path.exists(\"../data/MNIST/\")\n",
    "        full_train_set = torchvision.datasets.MNIST(\n",
    "            root=\"../data/\", train=True, download=download, transform=transform\n",
    "        )\n",
    "        full_test_set = torchvision.datasets.MNIST(\n",
    "            root=\"../data/\", train=False, transform=transform\n",
    "        )\n",
    "    elif ds_name == 'EMNIST':\n",
    "        # Might change split to \"balanced\" for balanced characters if performance is low\n",
    "        download = os.path.exists(\"../data/EMNIST/\")\n",
    "\n",
    "        full_train_set = torchvision.datasets.EMNIST(\n",
    "            root=\"../data/\", split=\"byclass\", download=download, transform=transform\n",
    "        )\n",
    "        full_test_set = torchvision.datasets.EMNIST(\n",
    "            root=\"../data/\", split=\"byclass\", download=download, transform=transform\n",
    "        )\n",
    "    else:\n",
    "        download = os.path.exists(\"../data/omniglot-py/\")\n",
    "\n",
    "        full_train_set = torchvision.datasets.Omniglot(\n",
    "            root=\"../data/\", download=download, transform=transform\n",
    "        )\n",
    "        full_test_set = torchvision.datasets.Omniglot(\n",
    "            root=\"../data/\", download=download, transform=transform\n",
    "        )\n",
    "    train_set, valid_set, _ = torch.utils.data.random_split(\n",
    "        full_train_set, [train_prop * keep_prop, (1 - train_prop) * keep_prop, 1-keep_prop]\n",
    "    )\n",
    "    test_set, _ = torch.utils.data.random_split(\n",
    "        full_test_set, [keep_prop, 1 - keep_prop]\n",
    "    )\n",
    "\n",
    "    print(\"Number of examples retained:\")\n",
    "    print(f\"  {len(train_set)} (training)\")\n",
    "    print(f\"  {len(valid_set)} (validation)\")\n",
    "    print(f\"  {len(test_set)} (test)\")\n",
    "\n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "train_set, valid_set, test_set = download_dataset(ds_name='EMNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "NUM_HIDDEN = 100\n",
    "NUM_INPUTS = np.prod(train_set.dataset.data[0].shape)\n",
    "NUM_OUTPUTS = len(train_set.dataset.classes)  # number of classes\n",
    "ACTIVATION = \"sigmoid\"  # output constrained between 0 and 1\n",
    "BIAS = False\n",
    "HMLP = HebbianMultiLayerPerceptron(\n",
    "    num_inputs=NUM_INPUTS,\n",
    "    num_outputs=NUM_OUTPUTS,\n",
    "    num_hidden=NUM_HIDDEN,\n",
    "    activation_type=ACTIVATION,\n",
    "    bias=BIAS,\n",
    ")\n",
    "MLP = MultiLayerPerceptron(\n",
    "    num_inputs=NUM_INPUTS,\n",
    "    num_outputs=NUM_OUTPUTS,\n",
    "    num_hidden=NUM_HIDDEN,\n",
    "    activation_type=ACTIVATION,\n",
    "    bias=BIAS,\n",
    ")\n",
    "\n",
    "hybrid_MLP = HybridMLP(MLP, HMLP, 'average')\n",
    "\n",
    "# Dataloaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_set, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### FUNCTIONS ########\n",
    "\n",
    "\n",
    "def train_model(MLP, train_loader, valid_loader, optimizer, num_epochs=5):\n",
    "    results_dict = {\n",
    "        \"avg_train_losses\": list(),\n",
    "        \"avg_valid_losses\": list(),\n",
    "        \"avg_train_accuracies\": list(),\n",
    "        \"avg_valid_accuracies\": list(),\n",
    "    }\n",
    "\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        no_train = True if e == 0 else False  # to get a baseline\n",
    "        latest_epoch_results_dict = train_epoch(\n",
    "            MLP, train_loader, valid_loader, optimizer=optimizer, no_train=no_train\n",
    "        )\n",
    "\n",
    "        for key, result in latest_epoch_results_dict.items():\n",
    "            if key in results_dict.keys() and isinstance(results_dict[key], list):\n",
    "                results_dict[key].append(latest_epoch_results_dict[key])\n",
    "            else:\n",
    "                results_dict[key] = result  # copy latest\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def train_epoch(MLP, train_loader, valid_loader, optimizer, no_train=False):\n",
    "\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "\n",
    "    epoch_results_dict = dict()\n",
    "    for dataset in [\"train\", \"valid\"]:\n",
    "        for sub_str in [\"correct_by_class\", \"seen_by_class\"]:\n",
    "            epoch_results_dict[f\"{dataset}_{sub_str}\"] = {\n",
    "                i: 0 for i in range(MLP.num_outputs)\n",
    "            }\n",
    "\n",
    "    MLP.train()\n",
    "    train_losses, train_acc = list(), list()\n",
    "    for X, y in train_loader:\n",
    "        y_pred = MLP(X, y=y)\n",
    "        loss = criterion(torch.log(y_pred), y)\n",
    "        acc = (torch.argmax(y_pred.detach(), axis=1) == y).sum() / len(y)\n",
    "        train_losses.append(loss.item() * len(y))\n",
    "        train_acc.append(acc.item() * len(y))\n",
    "        update_results_by_class_in_place(\n",
    "            y,\n",
    "            y_pred.detach(),\n",
    "            epoch_results_dict,\n",
    "            dataset=\"train\",\n",
    "            num_classes=MLP.num_outputs,\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        if not no_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    num_items = len(train_loader.dataset)\n",
    "    epoch_results_dict[\"avg_train_losses\"] = np.sum(train_losses) / num_items\n",
    "    epoch_results_dict[\"avg_train_accuracies\"] = np.sum(train_acc) / num_items * 100\n",
    "\n",
    "    MLP.eval()\n",
    "    valid_losses, valid_acc = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader:\n",
    "            y_pred = MLP(X)\n",
    "            loss = criterion(torch.log(y_pred), y)\n",
    "            acc = (torch.argmax(y_pred, axis=1) == y).sum() / len(y)\n",
    "            valid_losses.append(loss.item() * len(y))\n",
    "            valid_acc.append(acc.item() * len(y))\n",
    "            update_results_by_class_in_place(\n",
    "                y, y_pred.detach(), epoch_results_dict, dataset=\"valid\"\n",
    "            )\n",
    "\n",
    "    num_items = len(valid_loader.dataset)\n",
    "    epoch_results_dict[\"avg_valid_losses\"] = np.sum(valid_losses) / num_items\n",
    "    epoch_results_dict[\"avg_valid_accuracies\"] = np.sum(valid_acc) / num_items * 100\n",
    "\n",
    "    return epoch_results_dict\n",
    "\n",
    "\n",
    "def update_results_by_class_in_place(\n",
    "    y, y_pred, result_dict, dataset=\"train\", num_classes=10\n",
    "):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    for i in result_dict[f\"{dataset}_seen_by_class\"].keys():\n",
    "        idxs = np.where(y == int(i))[0]\n",
    "        result_dict[f\"{dataset}_seen_by_class\"][int(i)] += len(idxs)\n",
    "\n",
    "        num_correct = int(sum(y[idxs] == y_pred[idxs]))\n",
    "        result_dict[f\"{dataset}_correct_by_class\"][int(i)] += num_correct\n",
    "\n",
    "def evaluate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            y_pred = model(X)\n",
    "            predicted = torch.argmax(y_pred, axis=1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:21<00:00, 28.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 5.50%\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "backprop_optimizer = BasicOptimizer(hybrid_MLP.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "MLP_results_dict = train_model(\n",
    "    hybrid_MLP,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    optimizer=backprop_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")\n",
    "test_accuracy = evaluate_accuracy(hybrid_MLP, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m backprop_optimizer = BasicOptimizer(hybrid_MLP.parameters(), lr=LR)\n\u001b[32m      5\u001b[39m NUM_EPOCHS = \u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m MLP_results_dict = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhybrid_MLP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackprop_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m test_accuracy = evaluate_accuracy(hybrid_MLP, test_loader)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(MLP, train_loader, valid_loader, optimizer, num_epochs)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[32m     13\u001b[39m     no_train = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m e == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# to get a baseline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     latest_epoch_results_dict = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mMLP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_train\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, result \u001b[38;5;129;01min\u001b[39;00m latest_epoch_results_dict.items():\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m results_dict.keys() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results_dict[key], \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(MLP, train_loader, valid_loader, optimizer, no_train)\u001b[39m\n\u001b[32m     38\u001b[39m MLP.train()\n\u001b[32m     39\u001b[39m train_losses, train_acc = \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/predictive-feedback/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "backprop_optimizer = BasicOptimizer(hybrid_MLP.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "MLP_results_dict = train_model(\n",
    "    hybrid_MLP,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    optimizer=backprop_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    ")\n",
    "test_accuracy = evaluate_accuracy(hybrid_MLP, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
